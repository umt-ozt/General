{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from keras.layers import Dense, Input, InputLayer, Flatten, Conv2D, MaxPool2D\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we need to create image dataset from given folders. I deleted any other file except image folders not to take error \n",
    "# Images can be RGB or grayscale but they are grayscale in here!\n",
    "# we can resize the images.\n",
    "# Classes are planned as one-hot encoding  [class1,class2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in dataset, benign and malign image sizes were different so, I standardized it to an average value: 110.  \n",
    "IMG_HEIGHT = 110\n",
    "IMG_WIDTH = 110\n",
    "\n",
    "# this function unifies benign and malign data.\n",
    "def create_dataset(img_folder):\n",
    "   \n",
    "    img_data_array=[]\n",
    "    class_name=[]\n",
    "   \n",
    "    for dir1 in os.listdir(img_folder):\n",
    "        for file in os.listdir(os.path.join(img_folder, dir1)):\n",
    "            if dir1 == \"benign\":\n",
    "                image_path= os.path.join(img_folder, dir1,  file)\n",
    "                image= cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "                image=np.array(image)  # Ä± converted numpy array because it is appropriate for deep learning alg. input  \n",
    "                image = image.astype('float32')\n",
    "                image /= 255 # i scaled here \n",
    "                img_data_array.append(image)  # create image arrays\n",
    "                class_name.append([1,0])\n",
    "            elif dir1 == \"malignant\":  # same steps for beingn is applied here.\n",
    "                image_path= os.path.join(img_folder, dir1,  file)\n",
    "                image= cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "                image=np.array(image)\n",
    "                image = image.astype('float32')\n",
    "                image /= 255 \n",
    "                img_data_array.append(image)\n",
    "                class_name.append([0,1])  \n",
    "                \n",
    "    return img_data_array, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data, class_name = create_dataset(r'originals')   # we used breast cancer dataset. you can obtain from https://data.mendeley.com/datasets/wmy84gzngw/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(image_data)    # learn shape of image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data                 # shows how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion hierarchy: list ---> numpy.ndarray (do not forget reshape as follows. Parameters depend on data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data =np.array(image_data).reshape(np.array(image_data).shape[0],110,110,1)  # preparation of data for required dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_data)     # learn type of image data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(image_data)    # learn shape of image data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(image_data,\n",
    "class_name, train_size=0.75, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # here we start to construct our model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(InputLayer(input_shape=(300,300,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(50, kernel_size= (3,3), strides = (1,1), activation = 'relu', input_shape= (110,110,1)))  # essential layer for cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(3,3)))   # essential layer for cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())     # if you do not flatten probably you will take error. it depends on data structure needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(700, activation='relu'))     # add dense layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(2, activation='softmax'))    # add last dense layer that equals to number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')  # here there are optimizer alternatives to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 56s 19s/step - loss: 3.0937 - accuracy: 0.5401 - val_loss: 0.5170 - val_accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.8405 - accuracy: 0.6578 - val_loss: 1.7786 - val_accuracy: 0.3175\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.8828 - accuracy: 0.5561 - val_loss: 0.8179 - val_accuracy: 0.7143\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.7374 - accuracy: 0.6417 - val_loss: 0.5902 - val_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.4602 - accuracy: 0.7701 - val_loss: 0.3928 - val_accuracy: 0.8095\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3756 - accuracy: 0.8021 - val_loss: 0.3109 - val_accuracy: 0.8413\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2403 - accuracy: 0.9144 - val_loss: 0.3921 - val_accuracy: 0.8095\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2172 - accuracy: 0.9412 - val_loss: 0.2292 - val_accuracy: 0.9683\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1613 - accuracy: 0.9733 - val_loss: 0.2071 - val_accuracy: 0.9683\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 0.1330 - accuracy: 0.9840 - val_loss: 0.1914 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x200c4e87220>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(trainX), np.array(trainY), batch_size=64, epochs=10, validation_data=(np.array(testX),np.array(testY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict model:\n",
    "preds = model.predict(testX, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.95      0.98      0.97        43\n",
      "\n",
      "    accuracy                           0.95        63\n",
      "   macro avg       0.95      0.94      0.94        63\n",
      "weighted avg       0.95      0.95      0.95        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(classification_report(np.argmax(testY, axis=-1), np.argmax(preds, axis=-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
